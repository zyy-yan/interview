项目

恶意软件检测系统研究

这个项目是一个学术研究性质的一个项目，主要是研究Android下的恶意软件的检测。使用genymotion安卓模拟器，动态运行apk文件；使用ebpf工具动态监控运行的apk文件，从而获得恶意软件内核底层的相关行为特征；使用特征选择方法，进行数据处理，消除冗余特征；再使用机器学习分类算法进行分类训练。形成一个区别恶意软件和正常软件的分类器，到达检测恶意软件的目的，根据定义的相关指标得出检测效果。

主要负责：行为特征数据处理和分类训练检测。直接使用特征集作分类检测，检测效率和准确率稍低，使用特征选择方法卡方检验+主成分分析法对数据集进行处理，降低特征集维度，消除冗余特征。再进行分类测试。

1、伯克利包过滤器（Berkeley Packet Filter，缩写 BPF）是类 Unix 系统上数据链路层的一种原始接口，提供过滤报的方法。从 3.18 版本开始，Linux 内核提供了一种扩展的 BPF 虚拟机，被称为“extended BPF”，简称为 eBPF。它能够被用于非网络相关的功能，从而获取当前内核运行的许多信息 。

应用：eBPF 程序可以被设计用于各种各样的情形下，其分为两个应用领域。其中一个应用领域是内核跟踪和事件监控。BPF 程序可以被附着到静态 tracepoints 上或者动态探针（kprobe） 上，而且它与其它跟踪模式相比，有很多的优点。

另外一个应用领域是网络编程。除了套接字过滤器外，eBPF 程序还可以附加到 tc（Linux 流量控制工具）的入站或者出站接口上，以一种很高效的方式去执行各种包处理任务。

安全性：eBPF 不需要陷入内核便可通过编写函数从用户态获取内核态的相关数据，减少了陷入内核的消耗。eBPF 也是加强了在和用户空间交互的安全性。在内核中的检测器会拒绝加载引用了无效指针的字节码或者是以达到最大栈大小限制。循环也是不允许的（除非在编译时就知道是有常数上线的循环），字节码只能够调用一小部分指定的 eBPF 帮助函数。

使用 eBPF 提取内核更底层的特征，如内核函数调用、CPU 利用率等特征，网络流量、文件访问等特征
用机器学习算法进行分类检测。提高检测的效率，准确率，减少系统的资源消耗。

2、对通过ebpf拿到的一些数据做数据处理，拿到的数据中可能有些是对分类没有贡献，反而影响分类结果的特征，使用特征选择对拿到的数据，进行数据集降维，消除相关特征冗余。保证数据集的有效性和可靠性。

3、使用四种机器学习分类算法对数据集进行训练，定义评价指标，准确率、效率、误报率等，根据最终的分类结果，计算出评价指标。对比各种分类算法，得出最适合恶意软件检测的分类算法，最终进行分类检测。



Linux下轻量级web服务器

该项目是Linux下C++轻量级Web服务器的实现。使用线程池 +非阻塞socket + epoll+事件处理的并发模型；使用状态机解析HTTP请求报文，⽀持解析GET和POST请求；访问服务器数据库实现web端用户注册、登录功能，可以请求服务器图片和视频文件；实现同步/异步日志系统，记录服务器运行状态。

主要负责：访问服务器数据库的实现和日志系统的实现。

阻塞I/O

使用阻塞模式的套接字，开发网络程序比较简单，容易实现。当希望能够立即发送和接收数据，且处理的套接字数量比较少的情况下，使用阻塞模式来开发网络程序比较合适。

阻塞模式套接字的不足表现为，在大量建立好的套接字线程之间进行通信时比较困难。当使用“生产者-消费者”模型开发网络程序时，为每个套接字都分别分配一个读线程、一个处理数据线程和一个用于同步的事件，那么这样无疑加大系统的开销。其最大的缺点是当希望同时处理大量套接字时，将无从下手，其扩展性很差.

阻塞模式给网络编程带来了一个很大的问题，如在调用 send()的同时，线程将被阻塞，在此期间，线程将无法执行任何运算或响应任何的网络请求。这给多客户机、多业务逻辑的网络编程带来了挑战。

多线程的服务器模型似乎完美的解决了为多个客户机提供问答服务的要求，但其实并不尽然。如果要同时响应成百上千路的连接请求，则无论多线程还是多进程都会严重占据系统资源，降低系统对外界响应效率，而线程与进程本身也更容易进入假死状态。

由此可能会考虑使用“线程池”或“连接池”。“线程池”旨在减少创建和销毁线程的频率，其维持一定合理数量的线程，并让空闲的线程重新承担新的执行任务。“连接池”维持连接的缓存池，尽量重用已有的连接、减少创建和关闭连接的频率。这两种技术都可以很好的降低系统开销，都被广泛应用很多大型系统，如apache，mysql数据库等。

非阻塞I/O

非阻塞IO通过进程反复调用IO函数（多次系统调用，并马上返回）；在数据拷贝的过程中，进程是阻塞的；我们把一个SOCKET接口设置为非阻塞就是告诉内核，当所请求的I/O操作无法完成时，不要将进程睡眠，而是返回一个错误。这样我们的I/O操作函数将不断的测试数据是否已经准备好，如果没有准备好，继续测试，直到数据准备好为止。在这个不断测试的过程中，会大量的占用CPU的时间。



select：

select本质上是通过设置或者检查存放fd标志位的数据结构来进行下一步处理。这样所带来的缺点是：

- 单个进程可监视的fd数量被限制，即能监听端口的大小有限。 一般来说这个数目和系统内存关系很大，具体数目可以cat /proc/sys/fs/file-max察看。32位机默认是1024个。64位机默认是2048.

- 对socket进行扫描时是线性扫描，即采用轮询的方法，效率较低：当套接字比较多的时候，每次select()都要通过遍历FD_SETSIZE个Socket来完成调度,不管哪个Socket是活跃的,都遍历一遍。这会浪费很多CPU时间。如果能给套接字注册某个回调函数，当他们活跃时，自动完成相关操作，那就避免了轮询，这正是epoll与kqueue做的。

- 需要维护一个用来存放大量fd的数据结构，这样会使得用户空间和内核空间在传递该结构时复制开销大

poll：

poll本质上和select没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态，如果设备就绪则在设备等待队列中加入一项并继续遍历，如果遍历完所有fd后没有发现就绪设备，则挂起当前进程，直到设备就绪或者主动超时，被唤醒后它又要再次遍历fd。这个过程经历了多次无谓的遍历。

它没有最大连接数的限制，原因是它是基于链表来存储的，但是同样有一个缺点：

- 大量的fd的数组被整体复制于用户态和内核地址空间之间，而不管这样的复制是不是有意义。                                                                                                                               
- poll还有一个特点是“水平触发”，如果报告了fd后，没有被处理，那么下次poll时会再次报告该fd。

epoll:

epoll支持水平触发和边缘触发，最大的特点在于边缘触发，它只告诉进程哪些fd刚刚变为就需态，并且只会通知一次。还有一个特点是，epoll使用“事件”的就绪通知方式，通过epoll_ctl注册fd，一旦该fd就绪，内核就会采用类似callback的回调机制来激活该fd，epoll_wait便可以收到通知

epoll的优点：

- 没有最大并发连接的限制，能打开的FD的上限远大于1024（1G的内存上能监听约10万个端口）；
- 效率提升，不是轮询的方式，不会随着FD数目的增加效率下降。只有活跃可用的FD才会调用callback函数；
即Epoll最大的优点就在于它只管你“活跃”的连接，而跟连接总数无关，因此在实际的网络环境中，Epoll的效率就会远远高于select和poll。
- 内存拷贝，利用mmap()文件映射内存加速与内核空间的消息传递；即epoll使用mmap减少复制开销。

select、poll、epoll 区别总结：

1、支持一个进程所能打开的最大连接数

  select	单个进程所能打开的最大连接数有FD_SETSIZE宏定义，其大小是32个整数的大小（在32位的机器上，大小就是3232，同理64位机器上FD_SETSIZE为3264），当然我们可以对进行修改，然后重新编译内核，但是性能可能会受到影响，这需要进一步的测试。
  poll  	poll本质上和select没有区别，但是它没有最大连接数的限制，原因是它是基于链表来存储的
  epoll 	虽然连接数有上限，但是很大，1G内存的机器上可以打开10万左右的连接，2G内存的机器可以打开20万左右的连接

2、FD剧增后带来的IO效率问题

  select	因为每次调用时都会对连接进行线性遍历，所以随着FD的增加会造成遍历速度慢的“线性下降性能问题”。
  poll  	同上                                      
  epoll 	因为epoll内核中实现是根据每个fd上的callback函数来实现的，只有活跃的socket才会主动调用callback，所以在活跃socket较少的情况下，使用epoll没有前面两者的线性下降的性能问题，但是所有socket都很活跃的情况下，可能会有性能问题。

3、 消息传递方式

  select	内核需要将消息传递到用户空间，都需要内核拷贝动作 
  poll  	同上                       
  epoll 	epoll通过内核和用户空间共享一块内存来实现的。

总结：

综上，在选择select，poll，epoll时要根据具体的使用场合以及这三种方式的自身特点。

- 表面上看epoll的性能最好，但是在连接数少并且连接都十分活跃的情况下，select和poll的性能可能比epoll好，毕竟epoll的通知机制需要很多函数回调。

- select低效是因为每次它都需要轮询。但低效也是相对的，视情况而定，也可通过良好的设计改善

http解析：

根据状态转移,通过主从状态机封装了http连接类。其中,主状态机在内部调用从状态机,从状态机将处理状态和数据传给主状态机

客户端发出http连接请求

从状态机读取数据,更新自身状态和接收数据,传给主状态机

主状态机根据从状态机状态,更新自身状态,决定响应请求还是继续读取



服务器数据库模块:数据库连接使用单例模式，保证有唯一的连接对象。使用STL list容器实现数据库连接池，连接池的大小使用静态大小，使用互斥锁实现线程安全，在每次进行线程池操作之前进行加锁，操作完成之后解锁。web端的一个用户注册和用户登录，以及请求服务器中的图片及视频文件，http都采用post方式。



日志模块：同步/异步日志系统主要涉及了两个模块，一个是日志模块，一个是阻塞队列模块,其中加入阻塞队列模块主要是解决异步写入日志做准备.这里实现是使用的队列使STL中的queue为底层，使用单例模式确保全局只有唯一的一个对象，保证使用相同的队列；实现按天，行写入日志。



数学建模大赛

利用现有的统计数据建立简化的气候模型和极端天气模型。建立的模型区别于复杂的专业气候模型，有利于非专业人士理解和认识全球气候变化的态势，解释极端天气现象的发生，寻找、求证影响气候变化的因素，从而增强人们气候变化的意识。

问题一：挖掘加拿大地区温度的时空变化趋势、探索海洋表面温度变化规律

对加拿大地区整体气候进行分析，将整个加拿大的城市按地区与气候分为七个类别，并从每个类型的地区气候中挑选一个城市作为样本，探索温度变化规律。

从美国国家海洋和大气管理局（NOAA）官网筛选下载海洋表面温度（SST）历史数据，处理数据后对海洋表面温度变化建立模型，探索温度变化的规律。

使用线性倾向估计进行建模分析，得出加拿大地区的温度随着时间的推移，在显著性的上升。全球海洋表面温度也在在显著上升。

问题二：建立一个刻画气候变化的模型对未来25年的气候变化进行预测，该模型考虑地球的吸热、散热以及海洋的温度变化等要素。

根据分析气候变化原因，我们总结了四个影响气候变化的因素：太阳总辐照度、地球长波辐射、海洋表面温度和大气中温室气体含量。确定这四个维度，收集前30年的历史数据，使用岭估计模型和ARMA模型预测未来25年的气候变化。

问题三：“极寒天气”是某地的天气现象，这种极端气象的出现，与气候变化有无关系？请建立相应的模型，并利用题目所提供的数据以及你能收集的数据说明：全球变暖和局地极寒现象的出现之间是否矛盾？

使用显著性检验，定性的说局部地区的极寒天气与当地的气候类型有很大关系。各地地理因素差异较大，所以各地气候呈现出各自的变化特征，单单某些地区的极寒天气出现，并不能否认全球平均气温上升的趋势。


